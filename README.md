# ğŸ“– AI Scrape v12 - Agen Scraping Cerdas ğŸš€

<div align="center">
  <strong>ğŸš€ Sistem agen scraping semi-autonom dengan arsitektur client-server ğŸš€</strong><br>
  <em>ğŸ’¡ Otak AI di Vercel + Remote Control di Termux ğŸ’¡</em>
</div>

---

## ğŸ“Œ Daftar Isi

* [âœ¨ Konsep & Arsitektur](#-konsep--arsitektur)
* [ğŸŒŸ Fitur Unggulan](#-fitur-unggulan)
* [ğŸš€ Instalasi & Setup](#-instalasi--setup)

  * [ğŸ–¥ï¸ Backend (Otak di Vercel)](#ï¸-backend-otak-di-vercel)
  * [ğŸ“± Frontend CLI (Remote Control di Termux)](#-frontend-cli-remote-control-di-termux)
* [âš™ï¸ Cara Menggunakan](#ï¸-cara-menggunakan)
* [ğŸ“Š Workflow Penggunaan](#-workflow-penggunaan)
* [ğŸ› ï¸ Roadmap](#ï¸-roadmap)
* [â“ FAQ](#-faq)

---

## âœ¨ Konsep & Arsitektur

**AI Scrape v12** adalah agen scraping cerdas dengan desain **client-server**. Semua kerja berat (rendering, scraping, AI reasoning) dikerjakan oleh **backend di Vercel**, sementara pengguna cukup mengontrol lewat **CLI ringan di Termux/PC**.

### ğŸ”¹ Backend API ("Otak" di Vercel)

* Dibangun dengan **Node.js (Express) + Playwright**
* Analisa halaman + komunikasi dengan **Google Gemini AI**
* Headless scraping â†’ hasil dalam format JSON

### ğŸ”¹ Frontend CLI ("Remote Control")

* Dibangun dengan **Python (rich & questionary)**
* Tampilan interaktif dengan menu dinamis
* Kirim perintah ke backend, tampilkan hasil dengan UI rapi

```
+---------------------------------+      +--------------------------------+
|       REMOTE CONTROL (Termux)   |      |        OTAK AI (Vercel)        |
|---------------------------------|      |--------------------------------|
| - main.py (Python)              |      | - index.js (Node.js)           |
| - Input pengguna                |      | - Browser Headless (Playwright)|
| - Menu interaktif               |----->| - Analisa HTML + Gemini AI     |
| - Kirim perintah via HTTP       |<-----| - Scraping Data JSON           |
+---------------------------------+      +--------------------------------+
```

---

## ğŸŒŸ Fitur Unggulan

* âœ… **Failover Multi-Server** â†’ auto-switch jika server utama down
* âœ… **AI dengan Dua Mode**:

  * ğŸ›¸ *Co-pilot Penjelajah* â†’ untuk eksplorasi bebas
  * ğŸ¯ *GPS Pemburu* â†’ navigasi langsung ke target
* âœ… **Menu Kontekstual Cerdas** â†’ UI adaptif sesuai halaman
* âœ… **Scraping Multi-Lapis** (List â†’ Detail â†’ Chapter)
* âœ… **User Experience Natural** â†’ workflow mirip browsing asli

---

## ğŸš€ Instalasi & Setup

### ğŸ–¥ï¸ Backend (Otak di Vercel)

1. **Persiapkan Repository**

   * Clone project backend (misalnya `api-scrape`).
   * Pastikan file `index.js` dan dependensi sudah siap.

2. **Deploy ke Vercel**

   * Login ke [vercel.com](https://vercel.com).
   * Tambahkan project baru dari repo GitHub.
   * Pastikan platform otomatis mendeteksi Node.js.

3. **Atur Konfigurasi Vercel**

   * Pilih Node.js version **18.x** di Build Settings.
   * Tambahkan environment variables (misalnya `GEMINI_API_KEY`).
   * Tunggu hingga status deploy menjadi **Ready**.

4. **Catat URL Backend**

   * Salin URL produksi (misalnya `https://api-scrape.vercel.app`).
   * (Opsional) Deploy ke beberapa project untuk server cadangan.

---

### ğŸ“± Frontend CLI (Remote Control di Termux)

1. **Install Tools Wajib**

   * Install compiler & library dasar (contoh: `clang`, `openssl`).

2. **Install Dependensi Python**

   * Gunakan `requirements.txt` untuk menginstal library yang dibutuhkan.

3. **Buat File `.env`**

   * Masukkan URL backend dari langkah sebelumnya.
   * Bisa tambahkan lebih dari satu server untuk failover.

---

## âš™ï¸ Cara Menggunakan

1. Jalankan CLI dengan Python.
2. Pilih mode operasi (Co-pilot / GPS).
3. Navigasi menggunakan menu interaktif.
4. Hasil scraping ditampilkan langsung di terminal.

---

## ğŸ“Š Workflow Penggunaan

1. **Cari Komik/Item**
2. **Pilih dari daftar hasil**
3. **Scrape detail lengkap**
4. **Buka chapter dan ambil panel gambar**

Semua langkah bisa dilakukan dalam satu sesi tanpa restart.

---

## ğŸ› ï¸ Roadmap

* [ ] Integrasi penyimpanan hasil ke database (Supabase)
* [ ] Mode offline dengan cache lokal
* [ ] Ekspor hasil scraping ke PDF/EPUB
* [ ] Plugin tambahan untuk berbagai situs

---

## â“ FAQ

**Q: Bisa dijalankan di Windows/Linux selain Termux?**
A: Ya, CLI berbasis Python jadi fleksibel di semua OS.

**Q: Apakah scraping ini aman?**
A: Gunakan dengan bijak. Ikuti ketentuan situs target.

**Q: Apa keunggulan dibanding scraper biasa?**
A: Integrasi AI + failover server bikin lebih cerdas, stabil, dan fleksibel.

---

ğŸ‰ Selamat! Dengan **AI Scrape v12**, lo sekarang punya **agen scraping AI pribadi** yang modern dan siap tempur ğŸš€
